{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323e7126",
   "metadata": {},
   "source": [
    "# Vision Language Model Image Classification\n",
    "\n",
    "This notebook demonstrates how to use a Vision Language Model (Phi-4-multimodal) for image classification. The workflow includes:\n",
    "- Loading a pre-trained multimodal model that can process both images and text\n",
    "- Using in-context learning with example images to classify new images\n",
    "- Evaluating model performance on labeled data\n",
    "- Making predictions on new, unlabeled images\n",
    "\n",
    "The model uses few-shot learning, providing a few example images of each class to help guide predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aff865",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import essential libraries for image processing, data manipulation, and model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d22428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7a4fa",
   "metadata": {},
   "source": [
    "## 2. Configuration Settings\n",
    "\n",
    "Set the paths for your dataset and where to save the evaluation results:\n",
    "- **DATASET_PATH**: Path to your CSV file containing image paths and labels\n",
    "- **PERFORMANCE_SUMMARY_PATH**: Where to save the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "SETTINGS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "DATASET_PATH = './Datasets/Brand_Selfies/dataset.csv'\n",
    "PERFORMANCE_SUMMARY_PATH = './evaluation_summary_vlm.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d04b59",
   "metadata": {},
   "source": [
    "## 3. Load Vision Language Model and Define Helper Functions\n",
    "\n",
    "This cell performs several important tasks:\n",
    "\n",
    "**Metrics Computation** (`compute_weighted_metrics`):\n",
    "- Computes precision, recall, F1, and accuracy metrics for predictions\n",
    "- Handles unknown labels gracefully\n",
    "- Returns weighted metrics across all classes\n",
    "\n",
    "**Load Phi-4-Multimodal Model**:\n",
    "- Loads the Phi-4-multimodal model from Hugging Face\n",
    "- Uses GPU if available, falls back to CPU otherwise\n",
    "- This is a state-of-the-art vision language model that can understand both images and text\n",
    "\n",
    "**Few-Shot Learning Utilities**:\n",
    "- `get_prompt_with_examples_phi()`: Creates a prompt that includes example images and their labels, enabling few-shot learning\n",
    "- `predict_phi()`: Runs inference on a new image using the model with the example images as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fa401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_metrics(y_true: pd.Series, y_pred: pd.Series) -> dict:\n",
    "    precision_metric = load(\"precision\")\n",
    "    recall_metric = load(\"recall\")\n",
    "    f1_metric = load(\"f1\")\n",
    "    accuracy_metric = load(\"accuracy\")\n",
    "\n",
    "    y_true = y_true.astype(str)\n",
    "    y_pred = y_pred.astype(str)\n",
    "\n",
    "    labels = sorted(y_true.unique().tolist())\n",
    "    label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "    y_true = y_true.map(label2id)\n",
    "    y_pred = y_pred.map(label2id)\n",
    "\n",
    "    # Drop rows where prediction is not a known label\n",
    "    mask = y_pred.notna()\n",
    "    y_true = y_true[mask].astype(int)\n",
    "    y_pred = y_pred[mask].astype(int)\n",
    "\n",
    "    precision = precision_metric.compute(\n",
    "        predictions=y_pred, references=y_true, average=\"weighted\"\n",
    "    )[\"precision\"]\n",
    "    recall = recall_metric.compute(\n",
    "        predictions=y_pred, references=y_true, average=\"weighted\"\n",
    "    )[\"recall\"]\n",
    "    f1 = f1_metric.compute(\n",
    "        predictions=y_pred, references=y_true, average=\"weighted\"\n",
    "    )[\"f1\"]\n",
    "    accuracy = accuracy_metric.compute(\n",
    "        predictions=y_pred, references=y_true\n",
    "    )[\"accuracy\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_weighted\": precision,\n",
    "        \"recall_weighted\": recall,\n",
    "        \"f1_weighted\": f1,\n",
    "    }\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_path = \"microsoft/Phi-4-multimodal-instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16, \n",
    "    trust_remote_code=True, \n",
    ").cuda()\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(model_path)\n",
    "\n",
    "def get_prompt_with_examples_phi(base_prompt:str, df_example: pd.DataFrame):\n",
    "    prompt = ''\n",
    "    for i in df_example.index:\n",
    "        prompt = f\"{prompt}<|user|><|image_{i+1}|>{base_prompt}<|end|><|assistant|>'{df_example.at[i, 'label']}'<|end|>\"\n",
    "    prompt = f\"{prompt}<|user|><|image_{df_example.shape[0]+1}|>{base_prompt}<|end|><|assistant|>\"\n",
    "    return prompt\n",
    "\n",
    "def predict_phi(inference_img_path:str, prompt:str, example_images:list):\n",
    "    images = example_images.copy()\n",
    "    image_predict = Image.open(inference_img_path).convert('RGB')\n",
    "    images.append(image_predict)\n",
    "\n",
    "    inputs = processor(text=prompt, images=images, return_tensors='pt').to('cuda')\n",
    "    generate_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979f984",
   "metadata": {},
   "source": [
    "## 4. Load Your Dataset\n",
    "\n",
    "Load the CSV file containing your labeled images. Your dataset CSV must contain:\n",
    "- **image_path**: Path to each image file\n",
    "- **label**: The correct class label for that image\n",
    "\n",
    "The dataset is validated and displayed to confirm it loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "Loading your dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "required_cols = {'image_path', 'label'}\n",
    "assert required_cols.issubset(df.columns), \\\n",
    "    'Please make sure that your dataset contains both columns: image_path and label.'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2ee1b",
   "metadata": {},
   "source": [
    "## 5. Few-Shot Learning and Model Evaluation\n",
    "\n",
    "This cell performs the main classification and evaluation:\n",
    "\n",
    "1. **Extract Examples**: Selects one example image from each class to use for few-shot learning\n",
    "2. **Create Prompt**: Builds a prompt that includes the example images and their labels\n",
    "3. **Remove Examples from Evaluation Set**: Ensures examples don't appear in the test set\n",
    "4. **Inference**: Runs the model on each image in the dataset using the example images as context\n",
    "5. **Post-Processing**: Cleans up predictions by removing extra quotes and whitespace\n",
    "6. **Save Predictions**: Saves predictions to a CSV file\n",
    "7. **Compute Metrics**: Calculates performance metrics (accuracy, precision, recall, F1) and saves them\n",
    "\n",
    "The model uses the examples to understand the classification task and applies that knowledge to new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ddb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(df.label.unique())\n",
    "prompt = f'Assign the best fitting class to describe the image by choosing one of the following classes: {classes}'\n",
    "df_examples = df.groupby('label').apply(lambda x: x.sample(1, random_state=1)).reset_index(drop=True)\n",
    "df = df[~df[\"image_path\"].isin(df_examples[\"image_path\"])].reset_index(drop=True)\n",
    "assert not set(df_examples.image_path).intersection(set(df.image_path)), \"The example images should not be part of the evaluation dataset.\"\n",
    "n_examples = len(df_examples.label.unique())\n",
    "\n",
    "\n",
    "prompt_phi = get_prompt_with_examples_phi(prompt, df_examples)\n",
    "example_images = []\n",
    "for index in df_examples.index:\n",
    "    example_images.append(Image.open(df_examples.at[index, 'image_path']))\n",
    "\n",
    "for i in tqdm(df.index):\n",
    "    inference_image_path = df.at[i, 'image_path']\n",
    "    df.at[i, 'Pred_Phi'] = predict_phi(inference_image_path, prompt_phi, example_images)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        df.to_csv('dataset_vlm_predictions.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "df['Pred_Phi'] = df['Pred_Phi'].apply(lambda x: x.strip().strip(\"'\\\"\") if isinstance(x, str) else x)\n",
    "df.to_csv('./dataset_vlm_predictions.csv', index=False)\n",
    "\n",
    "metrics_rows = []\n",
    "for pred_col in [col for col in df.columns if 'Pred_' in col]:\n",
    "    if pred_col in df.columns:\n",
    "        mask = df[pred_col].notna()\n",
    "        metrics = compute_weighted_metrics(df.loc[mask, \"label\"], df.loc[mask, pred_col])\n",
    "        metrics_rows.append({\"model\": pred_col, **metrics})\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_rows)\n",
    "df_metrics.to_csv(PERFORMANCE_SUMMARY_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a1d32",
   "metadata": {},
   "source": [
    "## 6. Prepare Unlabeled Images for Prediction\n",
    "\n",
    "Load all images from the directory containing new, unseen examples that you want to classify. A DataFrame is created to store the image paths for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a6ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "prediction_image_paths = glob.glob('./Example_Dataset/Unseen_Samples/*')\n",
    "df_predictions = pd.DataFrame(prediction_image_paths, columns=['image_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1bb12",
   "metadata": {},
   "source": [
    "## 7. Run Inference on Unlabeled Images\n",
    "\n",
    "Process each unlabeled image through the trained vision language model to generate predictions:\n",
    "1. Uses the example images and prompt from earlier\n",
    "2. Runs the model in inference mode on each new image\n",
    "3. Extracts and cleans the predicted class label\n",
    "4. Saves all predictions to a CSV file\n",
    "\n",
    "The output CSV contains the image paths and their corresponding predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71583393",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(df_predictions.index):\n",
    "    df_predictions.at[i, 'Pred'] = predict_phi(df_predictions.at[i, 'image_path'], prompt_phi, example_images)\n",
    "\n",
    "df_predictions['Pred'] = df_predictions['Pred'].apply(lambda x: x.strip().strip(\"'\\\"\") if isinstance(x, str) else x)\n",
    "df_predictions.to_csv('./prediction_unseen_data_vlm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageBenchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
